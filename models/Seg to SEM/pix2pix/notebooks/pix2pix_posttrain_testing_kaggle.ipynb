{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2ca483",
   "metadata": {},
   "source": [
    "This notebook was executed in the Kaggle environment  \n",
    "using `/kaggle/input` datasets and saving outputs to `/kaggle/working`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ec12f",
   "metadata": {},
   "source": [
    "### copy checkpoints from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62469203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Locate checkpoints inside /kaggle/input and copy to /kaggle/working/checkpoints ===\n",
    "import glob, os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_ROOT = Path(\"/kaggle/input\")\n",
    "CKPT_ROOT  = Path(\"/kaggle/working/checkpoints\")\n",
    "CKPT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) First, search for latest_net_G.pth; if not found, take the most recent *_net_G.pth\n",
    "candidates = glob.glob(str(INPUT_ROOT / \"**/latest_net_G.pth\"), recursive=True)\n",
    "if not candidates:\n",
    "    candidates = glob.glob(str(INPUT_ROOT / \"**/*_net_G.pth\"), recursive=True)\n",
    "\n",
    "assert candidates, \"No model files found (latest_net_G.pth or *_net_G.pth) inside the input dataset.\"\n",
    "\n",
    "# 2) Select the most recently modified file\n",
    "candidates = sorted([Path(p) for p in candidates], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "best_G = candidates[0]\n",
    "exp_dir_in_input = best_G.parent           # experiment directory inside Input\n",
    "experiment_name  = exp_dir_in_input.name   # folder name (e.g. wafer_pix2pix_AtoB_256_out1)\n",
    "dst_exp_dir      = CKPT_ROOT / experiment_name\n",
    "\n",
    "print(\"Found model:\", best_G)\n",
    "print(\"Experiment directory:\", exp_dir_in_input)\n",
    "print(\"Destination:\", dst_exp_dir)\n",
    "\n",
    "# 3) Copy the entire experiment folder (files and subfolders)\n",
    "if dst_exp_dir.exists():\n",
    "    shutil.rmtree(dst_exp_dir)\n",
    "shutil.copytree(exp_dir_in_input, dst_exp_dir)\n",
    "\n",
    "# 4) Sanity check\n",
    "assert (dst_exp_dir/\"latest_net_G.pth\").exists() or any(dst_exp_dir.glob(\"*_net_G.pth\")), \\\n",
    "       \"No G.pth files were copied to the destination; make sure the dataset contains them.\"\n",
    "\n",
    "print(\"✅ Checkpoints successfully copied to:\", dst_exp_dir)\n",
    "!ls -lh {dst_exp_dir} | sed -n '1,200p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dominate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb7c3f",
   "metadata": {},
   "source": [
    "### run inference val sbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference on VAL (SBS) — matching the training config ===\n",
    "import sys, subprocess, shlex\n",
    "from pathlib import Path\n",
    "\n",
    "REPO       = Path(\"/kaggle/working/pix2pix\")\n",
    "DATAROOT   = Path(\"/kaggle/input/processed-images\")        # train/val/test in SBS format\n",
    "CKPT_ROOT  = Path(\"/kaggle/working/checkpoints\")\n",
    "\n",
    "# Select the most recently modified experiment folder\n",
    "exp_dirs = sorted([p for p in CKPT_ROOT.iterdir() if p.is_dir()],\n",
    "                  key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert exp_dirs, \"No experiment folder found in /kaggle/working/checkpoints\"\n",
    "EXPERIMENT = exp_dirs[0].name\n",
    "print(\"Running with experiment:\", EXPERIMENT)\n",
    "\n",
    "# Same parameters as in training\n",
    "INPUT_NC  = 3\n",
    "OUTPUT_NC = 1            # set to 3 if your SEM output is RGB\n",
    "DIRECTION = \"AtoB\"\n",
    "LOAD_SIZE = 286\n",
    "CROP_SIZE = 256\n",
    "\n",
    "# Restore the repo if missing\n",
    "if not REPO.exists():\n",
    "    !git clone --depth 1 https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git /kaggle/working/pix2pix\n",
    "\n",
    "# Ensure G exists\n",
    "assert (CKPT_ROOT/EXPERIMENT/\"latest_net_G.pth\").exists(), \"Missing latest_net_G.pth\"\n",
    "\n",
    "RESULTS = Path(\"/kaggle/working/inference_val_sbs\")\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, str(REPO/\"test.py\"),\n",
    "    \"--model\", \"pix2pix\",             # <<< Important: not 'test'!\n",
    "    \"--netG\", \"unet_256\",             # <<< must match training\n",
    "    \"--norm\", \"batch\",                # <<< same as training\n",
    "    \"--dataroot\", str(DATAROOT),\n",
    "    \"--phase\", \"val\",\n",
    "    \"--dataset_mode\", \"aligned\",\n",
    "    \"--direction\", DIRECTION,\n",
    "    \"--name\", EXPERIMENT,\n",
    "    \"--checkpoints_dir\", str(CKPT_ROOT),\n",
    "    \"--preprocess\", \"resize_and_crop\",\n",
    "    \"--load_size\", str(LOAD_SIZE),\n",
    "    \"--crop_size\", str(CROP_SIZE),\n",
    "    \"--input_nc\", str(INPUT_NC),\n",
    "    \"--output_nc\", str(OUTPUT_NC),\n",
    "    \"--serial_batches\",\n",
    "    \"--num_test\", \"100000\",\n",
    "    \"--results_dir\", str(RESULTS),\n",
    "    \"--epoch\", \"latest\",              # load the 'latest' checkpoint\n",
    "    \"--eval\",                         # disables dropout/bn training mode\n",
    "]\n",
    "\n",
    "print(\">>> TEST CMD:\\n\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "ret = subprocess.run(cmd, check=False)\n",
    "print(\"test.py exited with code:\", ret.returncode)\n",
    "\n",
    "print(\"\\nResults in:\", RESULTS)\n",
    "!find /kaggle/working/inference_val_sbs -maxdepth 3 -type f | sed -n '1,120p'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fedfd",
   "metadata": {},
   "source": [
    "### single image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Single-image inference using TestModel (A only) ===\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import sys, subprocess, shlex, glob\n",
    "\n",
    "REPO       = Path(\"/kaggle/working/pix2pix\")\n",
    "CKPT_ROOT  = Path(\"/kaggle/working/checkpoints\")\n",
    "EXPERIMENT = \"wafer_pix2pix_AtoB_256_out1\"\n",
    "\n",
    "INPUT_IMG  = Path(\"/kaggle/input/image10/image10.png\")\n",
    "TEMP_DIR   = Path(\"/kaggle/working/single_infer\")\n",
    "RESULTS    = Path(\"/kaggle/working/inference_single\")\n",
    "\n",
    "# Convert to PNG and save into a temporary dataroot folder\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "Image.open(INPUT_IMG).convert(\"RGB\").save(TEMP_DIR / \"test.png\")\n",
    "print(\"Input saved:\", TEMP_DIR/\"test.png\")\n",
    "\n",
    "# Clone repo if it doesn't exist in the current notebook\n",
    "if not REPO.exists():\n",
    "    !git clone --depth 1 https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git /kaggle/working/pix2pix\n",
    "\n",
    "# Run with --model test (not pix2pix), and same architecture arguments as training\n",
    "cmd = [\n",
    "    sys.executable, str(REPO/\"test.py\"),\n",
    "    \"--model\", \"test\",           # <<< Important: 'test' model doesn't require B\n",
    "    \"--netG\", \"unet_256\",        # must match training\n",
    "    \"--norm\", \"batch\",           # same as in training\n",
    "    \"--dataroot\", str(TEMP_DIR),\n",
    "    \"--dataset_mode\", \"single\",  # A only\n",
    "    \"--direction\", \"AtoB\",\n",
    "    \"--name\", EXPERIMENT,\n",
    "    \"--checkpoints_dir\", str(CKPT_ROOT),\n",
    "    \"--preprocess\", \"resize_and_crop\",\n",
    "    \"--load_size\", \"286\",\n",
    "    \"--crop_size\", \"256\",\n",
    "    \"--input_nc\", \"3\",\n",
    "    \"--output_nc\", \"1\",          # set to 3 if your SEM output is RGB\n",
    "    \"--results_dir\", str(RESULTS),\n",
    "    \"--epoch\", \"latest\",\n",
    "    \"--num_test\", \"1\",\n",
    "    \"--eval\",\n",
    "]\n",
    "print(\">>>\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "ret = subprocess.run(cmd, check=False)\n",
    "print(\"Exit code:\", ret.returncode)\n",
    "\n",
    "# Locate and display output images\n",
    "out_dir = RESULTS/EXPERIMENT/\"test_latest\"/\"images\"\n",
    "print(\"Results located in:\", out_dir)\n",
    "!ls -lh $out_dir | sed -n '1,200p'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c7458",
   "metadata": {},
   "source": [
    "##### display single inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d68ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"/kaggle/working/inference_single/wafer_pix2pix_AtoB_256_out1/test_latest/images\")\n",
    "\n",
    "imgA = Image.open(out_dir / \"test_real.png\")\n",
    "imgB = Image.open(out_dir / \"test_fake.png\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(imgA)\n",
    "plt.title(\"Input (Segmentation)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgB, cmap=\"gray\")\n",
    "plt.title(\"Generated SEM\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff24dcb",
   "metadata": {},
   "source": [
    "### run inference test sbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference on TEST (SBS) — matching training config ===\n",
    "import sys, subprocess, shlex\n",
    "from pathlib import Path\n",
    "\n",
    "REPO       = Path(\"/kaggle/working/pix2pix\")\n",
    "DATAROOT   = Path(\"/kaggle/input/processed-images\")  # train/val/test in SBS format\n",
    "CKPT_ROOT  = Path(\"/kaggle/working/checkpoints\")\n",
    "\n",
    "# Select the most recently modified experiment folder\n",
    "exp_dirs = sorted([p for p in CKPT_ROOT.iterdir() if p.is_dir()],\n",
    "                  key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert exp_dirs, \"No experiment folder found in /kaggle/working/checkpoints\"\n",
    "EXPERIMENT = exp_dirs[0].name\n",
    "print(\"Running with experiment:\", EXPERIMENT)\n",
    "\n",
    "# Parameters (same as in training)\n",
    "INPUT_NC  = 3\n",
    "OUTPUT_NC = 1       # set to 3 if your SEM is RGB\n",
    "DIRECTION = \"AtoB\"\n",
    "LOAD_SIZE = 286\n",
    "CROP_SIZE = 256\n",
    "\n",
    "# Clone repo if needed\n",
    "if not REPO.exists():\n",
    "    !git clone --depth 1 https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git /kaggle/working/pix2pix\n",
    "\n",
    "# Ensure generator exists\n",
    "assert (CKPT_ROOT/EXPERIMENT/\"latest_net_G.pth\").exists(), \"Missing latest_net_G.pth\"\n",
    "\n",
    "RESULTS = Path(\"/kaggle/working/inference_test_sbs\")\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, str(REPO/\"test.py\"),\n",
    "    \"--model\", \"pix2pix\",\n",
    "    \"--netG\", \"unet_256\",\n",
    "    \"--norm\", \"batch\",\n",
    "    \"--dataroot\", str(DATAROOT),\n",
    "    \"--phase\", \"test\",              # <<< now using test phase\n",
    "    \"--dataset_mode\", \"aligned\",\n",
    "    \"--direction\", DIRECTION,\n",
    "    \"--name\", EXPERIMENT,\n",
    "    \"--checkpoints_dir\", str(CKPT_ROOT),\n",
    "    \"--preprocess\", \"resize_and_crop\",\n",
    "    \"--load_size\", str(LOAD_SIZE),\n",
    "    \"--crop_size\", str(CROP_SIZE),\n",
    "    \"--input_nc\", str(INPUT_NC),\n",
    "    \"--output_nc\", str(OUTPUT_NC),\n",
    "    \"--serial_batches\",\n",
    "    \"--num_test\", \"100000\",\n",
    "    \"--results_dir\", str(RESULTS),\n",
    "    \"--epoch\", \"latest\",\n",
    "    \"--eval\",\n",
    "]\n",
    "\n",
    "print(\">>> TEST CMD:\\n\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "ret = subprocess.run(cmd, check=False)\n",
    "print(\"test.py exited with code:\", ret.returncode)\n",
    "\n",
    "print(\"\\nResults saved in:\", RESULTS)\n",
    "!find /kaggle/working/inference_test_sbs -maxdepth 3 -type f | sed -n '1,80p'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d4c76",
   "metadata": {},
   "source": [
    "### evaluate pix2pix metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Evaluation for Pix2Pix test_latest (PSNR, SSIM, LPIPS, FID)\n",
    "# ===========================\n",
    "# Imports\n",
    "!pip -q install lpips torch-fidelity >/dev/null\n",
    "\n",
    "import os, re, shutil, glob, math, json, pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import lpips\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from torch_fidelity import calculate_metrics\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Path configuration (adjust as needed)\n",
    "TEST_SBS_DIR = Path(\"/kaggle/input/processed-images/test\")  # not required for metric calculations\n",
    "RESULTS_DIR = Path(\"/kaggle/working/inference_test_sbs/wafer_pix2pix_AtoB_256_out1/test_latest/images\")\n",
    "OUT_DIR      = Path(\"/kaggle/working/eval_pix2pix_test\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Helper functions\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert('RGB')   # convert to RGB even if the source is grayscale\n",
    "    return np.array(img)\n",
    "\n",
    "def to_torch_lpips(arr_rgb_uint8):\n",
    "    # LPIPS expects a tensor in range [-1,1], shape NCHW, RGB order\n",
    "    ten = torch.from_numpy(arr_rgb_uint8.astype(np.float32)/255.0)      # HWC, [0,1]\n",
    "    ten = ten.permute(2,0,1).unsqueeze(0)                               # 1x3xHxW\n",
    "    ten = ten*2-1                                                       # [-1,1]\n",
    "    return ten\n",
    "\n",
    "# ---- Find fake_B / real_B pairs based on filenames\n",
    "# In standard pix2pix output, file names follow the pattern: xxx_fake_B.png, xxx_real_B.png\n",
    "fake_paths = sorted(RESULTS_DIR.glob(\"*_fake_B.*\"))\n",
    "pairs = []\n",
    "for fp in fake_paths:\n",
    "    base = re.sub(r\"_fake_B\\.[^.]+$\", \"\", fp.name)\n",
    "    # try to find matching ground truth\n",
    "    cand = list(RESULTS_DIR.glob(base + \"_real_B.*\"))\n",
    "    if cand:\n",
    "        pairs.append((fp, cand[0]))\n",
    "\n",
    "assert len(pairs) > 0, f\"No Fake/Real pairs found in: {RESULTS_DIR}\"\n",
    "\n",
    "# ---- Initialize LPIPS\n",
    "lpips_model = lpips.LPIPS(net='alex').eval()\n",
    "\n",
    "# ---- Compute metrics for each image pair\n",
    "rows = []\n",
    "for fp, rp in pairs:\n",
    "    fake = load_image(fp)\n",
    "    real = load_image(rp)\n",
    "    # Ensure same dimensions\n",
    "    if fake.shape != real.shape:\n",
    "        # If there's a minor mismatch, resize to GT size\n",
    "        real_h, real_w = real.shape[:2]\n",
    "        fake = np.array(Image.fromarray(fake).resize((real_w, real_h), Image.BICUBIC))\n",
    "\n",
    "    # PSNR / SSIM (computed on RGB; for grayscale, convert both to gray)\n",
    "    cur_psnr = psnr(real, fake, data_range=255)\n",
    "    cur_ssim = ssim(real, fake, channel_axis=2, data_range=255)\n",
    "\n",
    "    # LPIPS\n",
    "    with torch.no_grad():\n",
    "        t_fake = to_torch_lpips(fake)\n",
    "        t_real = to_torch_lpips(real)\n",
    "        cur_lpips = float(lpips_model(t_fake, t_real).cpu().numpy())\n",
    "\n",
    "    rows.append({\n",
    "        \"name\": fp.stem.replace(\"_fake_B\",\"\"),\n",
    "        \"psnr\": cur_psnr,\n",
    "        \"ssim\": cur_ssim,\n",
    "        \"lpips\": cur_lpips\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"name\")\n",
    "df.to_csv(OUT_DIR/\"metrics_per_image.csv\", index=False)\n",
    "\n",
    "# ---- Summary (mean and std)\n",
    "summary = {\n",
    "    \"N\": len(df),\n",
    "    \"PSNR_mean\": df.psnr.mean(), \"PSNR_std\": df.psnr.std(),\n",
    "    \"SSIM_mean\": df.ssim.mean(), \"SSIM_std\": df.ssim.std(),\n",
    "    \"LPIPS_mean\": df.lpips.mean(), \"LPIPS_std\": df.lpips.std(),\n",
    "}\n",
    "with open(OUT_DIR/\"metrics_summary.json\",\"w\") as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Summary:\", summary)\n",
    "\n",
    "# ---- Plots\n",
    "plt.figure(); df.psnr.hist(bins=40); plt.title(\"PSNR distribution\"); plt.xlabel(\"PSNR (dB)\"); plt.ylabel(\"count\"); plt.show()\n",
    "plt.figure(); df.ssim.hist(bins=40); plt.title(\"SSIM distribution\"); plt.xlabel(\"SSIM\"); plt.ylabel(\"count\"); plt.show()\n",
    "plt.figure(); df.lpips.hist(bins=40); plt.title(\"LPIPS distribution\"); plt.xlabel(\"LPIPS (lower is better)\"); plt.ylabel(\"count\"); plt.show()\n",
    "\n",
    "# ---- FID: requires two folders (real and fake)\n",
    "fid_real_dir = OUT_DIR/\"fid_real\"; fid_fake_dir = OUT_DIR/\"fid_fake\"\n",
    "for d in [fid_real_dir, fid_fake_dir]:\n",
    "    if d.exists(): shutil.rmtree(d)\n",
    "    d.mkdir(parents=True)\n",
    "\n",
    "for fp, rp in pairs:\n",
    "    shutil.copy(rp, fid_real_dir/(Path(fp).stem.replace(\"_fake_B\",\"\") + rp.suffix))\n",
    "    shutil.copy(fp, fid_fake_dir/(Path(fp).stem.replace(\"_fake_B\",\"\") + fp.suffix))\n",
    "\n",
    "metrics = calculate_metrics(input1=fid_fake_dir.as_posix(),\n",
    "                            input2=fid_real_dir.as_posix(),\n",
    "                            cuda=torch.cuda.is_available(),\n",
    "                            isc=False, kid=True, fid=True, verbose=False)\n",
    "with open(OUT_DIR/\"fid_kid.json\",\"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"FID/KID:\", metrics)\n",
    "print(f\"\\nOutput files:\\n- {OUT_DIR/'metrics_per_image.csv'}\\n- {OUT_DIR/'metrics_summary.json'}\\n- {OUT_DIR/'fid_kid.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db7030",
   "metadata": {},
   "source": [
    "#### evaluate pix2pix metrics 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cbe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Evaluation for Pix2Pix test_latest (PSNR, SSIM, LPIPS, FID, KID on 300)\n",
    "# ===========================\n",
    "!pip -q install lpips torch-fidelity >/dev/null\n",
    "\n",
    "import os, re, shutil, glob, math, json, pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import lpips\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from torch_fidelity import calculate_metrics\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Path configuration\n",
    "TEST_SBS_DIR = Path(\"/kaggle/input/processed-images/test\")  # not required for metric evaluation\n",
    "RESULTS_DIR  = Path(\"/kaggle/working/inference_test_sbs/wafer_pix2pix_AtoB_256_out1/test_latest/images\")\n",
    "OUT_DIR      = Path(\"/kaggle/working/eval_pix2pix_test\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Helper functions\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    return np.array(img)\n",
    "\n",
    "def to_torch_lpips(arr_rgb_uint8):\n",
    "    ten = torch.from_numpy(arr_rgb_uint8.astype(np.float32)/255.0)  # HWC, [0,1]\n",
    "    ten = ten.permute(2,0,1).unsqueeze(0)                           # 1x3xHxW\n",
    "    ten = ten*2-1                                                   # [-1,1]\n",
    "    return ten\n",
    "\n",
    "# ---- Find fake_B / real_B pairs\n",
    "fake_paths = sorted(RESULTS_DIR.glob(\"*_fake_B.*\"))\n",
    "pairs = []\n",
    "for fp in fake_paths:\n",
    "    base = re.sub(r\"_fake_B\\.[^.]+$\", \"\", fp.name)\n",
    "    cand = list(RESULTS_DIR.glob(base + \"_real_B.*\"))\n",
    "    if cand:\n",
    "        pairs.append((fp, cand[0]))\n",
    "\n",
    "assert len(pairs) > 0, f\"No Fake/Real pairs found in: {RESULTS_DIR}\"\n",
    "print(f\"Found {len(pairs)} pairs for evaluation.\")\n",
    "\n",
    "# ---- LPIPS\n",
    "lpips_model = lpips.LPIPS(net='alex').eval()\n",
    "\n",
    "# ---- Compute metrics for each image\n",
    "rows = []\n",
    "for fp, rp in pairs:\n",
    "    fake = load_image(fp)\n",
    "    real = load_image(rp)\n",
    "\n",
    "    if fake.shape != real.shape:\n",
    "        real_h, real_w = real.shape[:2]\n",
    "        fake = np.array(Image.fromarray(fake).resize((real_w, real_h), Image.BICUBIC))\n",
    "\n",
    "    cur_psnr = psnr(real, fake, data_range=255)\n",
    "    cur_ssim = ssim(real, fake, channel_axis=2, data_range=255)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t_fake = to_torch_lpips(fake)\n",
    "        t_real = to_torch_lpips(real)\n",
    "        cur_lpips = lpips_model(t_fake, t_real).item()  # fixed deprecation warning\n",
    "\n",
    "    rows.append({\n",
    "        \"name\": fp.stem.replace(\"_fake_B\",\"\"),\n",
    "        \"psnr\": cur_psnr,\n",
    "        \"ssim\": cur_ssim,\n",
    "        \"lpips\": cur_lpips\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"name\")\n",
    "df.to_csv(OUT_DIR/\"metrics_per_image.csv\", index=False)\n",
    "\n",
    "summary = {\n",
    "    \"N\": len(df),\n",
    "    \"PSNR_mean\": df.psnr.mean(), \"PSNR_std\": df.psnr.std(),\n",
    "    \"SSIM_mean\": df.ssim.mean(), \"SSIM_std\": df.ssim.std(),\n",
    "    \"LPIPS_mean\": df.lpips.mean(), \"LPIPS_std\": df.lpips.std(),\n",
    "}\n",
    "with open(OUT_DIR/\"metrics_summary.json\",\"w\") as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Summary:\", summary)\n",
    "\n",
    "# ---- Plots\n",
    "plt.figure(); df.psnr.hist(bins=40); plt.title(\"PSNR distribution\"); plt.xlabel(\"PSNR (dB)\"); plt.ylabel(\"count\"); plt.show()\n",
    "plt.figure(); df.ssim.hist(bins=40); plt.title(\"SSIM distribution\"); plt.xlabel(\"SSIM\"); plt.ylabel(\"count\"); plt.show()\n",
    "plt.figure(); df.lpips.hist(bins=40); plt.title(\"LPIPS distribution\"); plt.xlabel(\"LPIPS (lower is better)\"); plt.ylabel(\"count\"); plt.show()\n",
    "\n",
    "# ---- FID/KID: build real/fake folders\n",
    "fid_real_dir = OUT_DIR/\"fid_real\"; fid_fake_dir = OUT_DIR/\"fid_fake\"\n",
    "for d in [fid_real_dir, fid_fake_dir]:\n",
    "    if d.exists(): shutil.rmtree(d)\n",
    "    d.mkdir(parents=True)\n",
    "\n",
    "for fp, rp in pairs:\n",
    "    shutil.copy(rp, fid_real_dir/(Path(fp).stem.replace(\"_fake_B\",\"\") + rp.suffix))\n",
    "    shutil.copy(fp, fid_fake_dir/(Path(fp).stem.replace(\"_fake_B\",\"\") + fp.suffix))\n",
    "\n",
    "# --- Compute FID + KID where KID subset <= number of examples (here 300)\n",
    "kid_subset = min(300, len(pairs))  # if fewer than 300, automatically adjusts\n",
    "metrics = calculate_metrics(\n",
    "    input1=fid_fake_dir.as_posix(),\n",
    "    input2=fid_real_dir.as_posix(),\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    isc=False,\n",
    "    fid=True,\n",
    "    kid=True,\n",
    "    kid_subset_size=kid_subset,\n",
    "    kid_subset_retries=10,   # improves statistical stability\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "with open(OUT_DIR/\"fid_kid.json\",\"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"FID/KID:\", metrics)\n",
    "print(f\"\\nOutput files:\\n- {OUT_DIR/'metrics_per_image.csv'}\\n- {OUT_DIR/'metrics_summary.json'}\\n- {OUT_DIR/'fid_kid.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d98b2",
   "metadata": {},
   "source": [
    "### show worst three panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Show worst-3 per metric (PSNR↓, SSIM↓, LPIPS↑)\n",
    "# Saves panels to OUT_DIR and displays them inline\n",
    "# ===========================\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re, itertools\n",
    "\n",
    "def load_img(path):\n",
    "    return np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "def try_find(path_pattern_list):\n",
    "    for p in path_pattern_list:\n",
    "        matches = list(p.parent.glob(p.name))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "# Build quick index: name -> {fake, realB, realA?}\n",
    "index = {}\n",
    "for fp, rp in pairs:\n",
    "    name = Path(fp).stem.replace(\"_fake_B\",\"\")\n",
    "    rec = index.setdefault(name, {})\n",
    "    rec[\"fake\"] = fp\n",
    "    rec[\"realB\"] = rp\n",
    "    # try to find real_A next to them\n",
    "    base = re.sub(r\"_fake_B\\.[^.]+$\", \"\", fp.name)\n",
    "    candA = list(RESULTS_DIR.glob(base + \"_real_A.*\"))\n",
    "    if candA:\n",
    "        rec[\"realA\"] = candA[0]\n",
    "\n",
    "def safe_resize_like(img_src, img_ref):\n",
    "    if img_src.shape[:2] != img_ref.shape[:2]:\n",
    "        h, w = img_ref.shape[:2]\n",
    "        img_src = np.array(Image.fromarray(img_src).resize((w, h), Image.BICUBIC))\n",
    "    return img_src\n",
    "\n",
    "def show_worst(metric_name, worst_df, save_name):\n",
    "    rows = len(worst_df)\n",
    "    cols = 4  # InputA | FakeB | RealB | |Diff|\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3.5*rows))\n",
    "    if rows == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    titles = [\"Input A\", \"Fake B\", \"Real B\", \"|Fake-Real|\"]\n",
    "    for r, (_, row) in enumerate(worst_df.iterrows()):\n",
    "        name = row[\"name\"]\n",
    "        rec = index[name]\n",
    "        img_fake = load_img(rec[\"fake\"])\n",
    "        img_real = load_img(rec[\"realB\"])\n",
    "        img_fake = safe_resize_like(img_fake, img_real)\n",
    "\n",
    "        # Input A (optional)\n",
    "        if \"realA\" in rec:\n",
    "            img_A = load_img(rec[\"realA\"])\n",
    "            img_A = safe_resize_like(img_A, img_real)\n",
    "        else:\n",
    "            img_A = None\n",
    "\n",
    "        # |Diff| as grayscale heat\n",
    "        diff = np.mean(np.abs(img_fake.astype(np.float32) - img_real.astype(np.float32)), axis=2)\n",
    "        # normalize for display\n",
    "        if diff.max() > 0:\n",
    "            diff_disp = (diff / diff.max())\n",
    "        else:\n",
    "            diff_disp = diff\n",
    "\n",
    "        imgs = [img_A, img_fake, img_real, diff_disp]\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c]\n",
    "            ax.axis(\"off\")\n",
    "            if c == 0 and imgs[c] is None:\n",
    "                ax.set_title(f\"{titles[c]} (missing)\", fontsize=11)\n",
    "                continue\n",
    "            if c == 3:\n",
    "                im = ax.imshow(imgs[c], cmap=\"inferno\")\n",
    "            else:\n",
    "                im = ax.imshow(imgs[c])\n",
    "            if r == 0:\n",
    "                ax.set_title(titles[c], fontsize=12)\n",
    "\n",
    "        # row label with metric value\n",
    "        val_str = f\"{metric_name}=\"\n",
    "        if metric_name.lower() == \"lpips\":\n",
    "            val_str += f\"{row['lpips']:.4f}\"\n",
    "        elif metric_name.lower() == \"psnr\":\n",
    "            val_str += f\"{row['psnr']:.2f} dB\"\n",
    "        elif metric_name.lower() == \"ssim\":\n",
    "            val_str += f\"{row['ssim']:.4f}\"\n",
    "        fig.text(0.01, 1 - (r+0.5)/rows, f\"{r+1}. {name}  |  {val_str}\", va=\"center\", fontsize=11)\n",
    "\n",
    "    fig.suptitle(f\"Worst 3 by {metric_name}\", fontsize=14, y=0.995)\n",
    "    plt.tight_layout(rect=[0,0,1,0.97])\n",
    "    out_path = OUT_DIR / save_name\n",
    "    plt.savefig(out_path, dpi=130)\n",
    "    plt.show()\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# pick worst-3 per metric\n",
    "worst_ssim  = df.nsmallest(3, \"ssim\")\n",
    "worst_psnr  = df.nsmallest(3, \"psnr\")\n",
    "worst_lpips = df.nlargest(3, \"lpips\")\n",
    "\n",
    "print(\"Worst by SSIM:\")\n",
    "print(worst_ssim[[\"name\",\"ssim\"]])\n",
    "print(\"\\nWorst by PSNR:\")\n",
    "print(worst_psnr[[\"name\",\"psnr\"]])\n",
    "print(\"\\nWorst by LPIPS:\")\n",
    "print(worst_lpips[[\"name\",\"lpips\"]])\n",
    "\n",
    "# show/save panels\n",
    "show_worst(\"SSIM\", worst_ssim,  \"worst3_ssim.png\")\n",
    "show_worst(\"PSNR\", worst_psnr,  \"worst3_psnr.png\")\n",
    "show_worst(\"LPIPS\", worst_lpips, \"worst3_lpips.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dca82",
   "metadata": {},
   "source": [
    "### batch inference and grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Batch inference on folder (A-only) + side-by-side grids ===\n",
    "# Input:  /kaggle/input/preds-yael  (a folder of single images, not SBS)\n",
    "# Output: /kaggle/working/inference_preds_yael/<EXP>/test_latest/images\n",
    "# Grids:  /kaggle/working/preds_yael_grids\n",
    "# ZIPs for download: /kaggle/working/preds_yael_results.zip , preds_yael_grids.zip\n",
    "!pip -q install dominate\n",
    "\n",
    "import os, glob, shutil, subprocess, shlex\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Settings ----------\n",
    "INPUT_DS   = Path(\"/kaggle/input/preds-yael\")  # ← your folder with input images\n",
    "REPO       = Path(\"/kaggle/working/pix2pix\")\n",
    "# Detect where checkpoints are:\n",
    "CKPT_WORK  = Path(\"/kaggle/working/checkpoints\")\n",
    "CKPT_INPUT = Path(\"/kaggle/input/wafer-pix2pix-checkpoints\")\n",
    "\n",
    "if CKPT_WORK.exists():\n",
    "    CKPT_ROOT = CKPT_WORK\n",
    "else:\n",
    "    CKPT_ROOT = CKPT_INPUT\n",
    "assert CKPT_ROOT.exists(), f\"Checkpoint directory not found: {CKPT_ROOT}\"\n",
    "\n",
    "# Find the experiment folder (the one containing latest_net_G.pth)\n",
    "def find_experiment_dir(root: Path):\n",
    "    cands = []\n",
    "    # search up to depth 2\n",
    "    for p in root.glob(\"*\"):\n",
    "        if p.is_dir() and (p/\"latest_net_G.pth\").exists():\n",
    "            cands.append(p)\n",
    "    if not cands:\n",
    "        for p in root.glob(\"*/*\"):\n",
    "            if p.is_dir() and (p/\"latest_net_G.pth\").exists():\n",
    "                cands.append(p)\n",
    "    assert cands, f\"latest_net_G.pth not found under {root}\"\n",
    "    # pick the most recently modified\n",
    "    cands = sorted(cands, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    return cands[0]\n",
    "\n",
    "EXP_DIR    = find_experiment_dir(CKPT_ROOT)\n",
    "EXPERIMENT = EXP_DIR.name\n",
    "print(\"Selected experiment:\", EXPERIMENT)\n",
    "print(\"Checkpoints under:\", EXP_DIR)\n",
    "\n",
    "# Parameters (match training):\n",
    "INPUT_NC   = 3\n",
    "OUTPUT_NC  = 1     # set to 3 if your SEM output is RGB\n",
    "DIRECTION  = \"AtoB\"\n",
    "LOAD_SIZE  = 286\n",
    "CROP_SIZE  = 256\n",
    "\n",
    "# ---------- Prepare repo ----------\n",
    "if not REPO.exists():\n",
    "    !git clone --depth 1 https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git /kaggle/working/pix2pix\n",
    "\n",
    "# ---------- Collect input images and convert to PNG in a working folder ----------\n",
    "TEMP_DIR   = Path(\"/kaggle/working/preds_yael_input\")\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
    "src_imgs = []\n",
    "for ext in exts:\n",
    "    src_imgs += sorted(INPUT_DS.rglob(f\"*{ext}\"))\n",
    "\n",
    "assert src_imgs, f\"No images found under {INPUT_DS}\"\n",
    "print(f\"Found {len(src_imgs)} images. Converting and saving as PNG...\")\n",
    "\n",
    "# clean first\n",
    "for p in TEMP_DIR.glob(\"*\"):\n",
    "    p.unlink()\n",
    "\n",
    "name_map = {}  # mapping: base-name → source (for grids/display)\n",
    "for i, p in enumerate(src_imgs, 1):\n",
    "    try:\n",
    "        im = Image.open(p).convert(\"RGB\")\n",
    "        # Save as \"imgNNNN.png\" to avoid issues with special filenames\n",
    "        out_name = f\"img_{i:05d}.png\"\n",
    "        im.save(TEMP_DIR / out_name)\n",
    "        name_map[out_name.replace(\".png\",\"\")] = p\n",
    "    except Exception as e:\n",
    "        print(\"Skipping problematic file:\", p, e)\n",
    "\n",
    "print(\"Converted and saved:\", len(name_map))\n",
    "\n",
    "# ---------- Run test.py with single dataset_mode + model=test (A only) ----------\n",
    "RESULTS = Path(\"/kaggle/working/inference_preds_yael\")\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    \"/usr/bin/python3\", str(REPO/\"test.py\"),\n",
    "    \"--model\", \"test\",               # Important: use 'test' (not pix2pix) when B is absent\n",
    "    \"--netG\", \"unet_256\",\n",
    "    \"--norm\", \"batch\",\n",
    "    \"--dataroot\", str(TEMP_DIR),\n",
    "    \"--dataset_mode\", \"single\",      # A only\n",
    "    \"--direction\", DIRECTION,\n",
    "    \"--name\", EXPERIMENT,\n",
    "    \"--checkpoints_dir\", str(CKPT_ROOT),\n",
    "    \"--preprocess\", \"resize_and_crop\",\n",
    "    \"--load_size\", str(LOAD_SIZE),\n",
    "    \"--crop_size\", str(CROP_SIZE),\n",
    "    \"--input_nc\", str(INPUT_NC),\n",
    "    \"--output_nc\", str(OUTPUT_NC),\n",
    "    \"--results_dir\", str(RESULTS),\n",
    "    \"--epoch\", \"latest\",\n",
    "    \"--num_test\", \"100000\",\n",
    "    \"--eval\",\n",
    "]\n",
    "print(\">>>\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "ret = subprocess.run(cmd, check=False)\n",
    "print(\"Exit code:\", ret.returncode)\n",
    "assert ret.returncode == 0, \"test.py failed — check logs above\"\n",
    "\n",
    "# ---------- Locate the produced images folder ----------\n",
    "images_dirs = list(RESULTS.glob(f\"{EXPERIMENT}/test_latest/images\"))\n",
    "assert images_dirs, f\"'images' folder not found under {RESULTS}\"\n",
    "IMDIR = images_dirs[0]\n",
    "print(\"Output folder:\", IMDIR)\n",
    "\n",
    "# ---------- Build grids (Input | Output) and save ----------\n",
    "GRIDS_DIR = Path(\"/kaggle/working/preds_yael_grids\")\n",
    "GRIDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fake_list = sorted(IMDIR.glob(\"*_fake.png\"))\n",
    "shown = 0\n",
    "\n",
    "for fake_path in fake_list:\n",
    "    stem = fake_path.name.replace(\"_fake.png\",\"\")\n",
    "    real_path = IMDIR / f\"{stem}_real.png\"\n",
    "    if not real_path.exists():\n",
    "        continue\n",
    "    # load\n",
    "    A = Image.open(real_path).convert(\"RGB\")\n",
    "    B = Image.open(fake_path)\n",
    "    # normalize for uniform display\n",
    "    A_show = A.resize((256,256))\n",
    "    # if grayscale, show with gray-like look — but grids are saved in RGB\n",
    "    if B.mode != \"RGB\":\n",
    "        B_show = B.convert(\"L\").resize((256,256))\n",
    "        B_show = Image.merge(\"RGB\", (B_show, B_show, B_show))\n",
    "    else:\n",
    "        B_show = B.resize((256,256))\n",
    "    # grid\n",
    "    W = Image.new(\"RGB\", (256*2, 256))\n",
    "    W.paste(A_show, (0,0))\n",
    "    W.paste(B_show, (256,0))\n",
    "    grid_name = f\"{stem}_grid.png\"\n",
    "    W.save(GRIDS_DIR / grid_name)\n",
    "\n",
    "print(f\"Grids saved under: {GRIDS_DIR}\")\n",
    "\n",
    "# ---------- Display in notebook (first 12 examples to avoid clutter) ----------\n",
    "to_show = sorted(GRIDS_DIR.glob(\"*_grid.png\"))[:12]\n",
    "fig, axes = plt.subplots(len(to_show), 1, figsize=(7, 3*len(to_show)))\n",
    "if len(to_show) == 1:\n",
    "    axes = [axes]\n",
    "for ax, p in zip(axes, to_show):\n",
    "    ax.imshow(Image.open(p))\n",
    "    ax.set_title(p.name)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Create ZIPs for download ----------\n",
    "# All inference results\n",
    "!cd /kaggle/working && zip -r -q preds_yael_results.zip inference_preds_yael\n",
    "# All grids\n",
    "!cd /kaggle/working && zip -r -q preds_yael_grids.zip preds_yael_grids\n",
    "print(\"\\nDownload from:\")\n",
    "print(\"/kaggle/working/preds_yael_results.zip\")\n",
    "print(\"/kaggle/working/preds_yael_grids.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6459356",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
