{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ddf2171",
   "metadata": {},
   "source": [
    "This notebook was executed in the Kaggle environment  \n",
    "using `/kaggle/input` datasets and saving outputs to `/kaggle/working`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a18665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Pix2Pix on Kaggle with Auto-Resume via Private Kaggle Dataset (FIXED)\n",
    "# - Handles initial 404 by polling for dataset readiness\n",
    "# - Removes deprecated --display_id flag\n",
    "# ============================================================\n",
    "import os, sys, json, time, shlex, subprocess, threading, zipfile, glob, re\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- USER CONFIG ----------\n",
    "GIT_URL          = \"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\"\n",
    "REPO             = Path(\"/kaggle/working/pix2pix\")\n",
    "DATAROOT         = Path(\"/kaggle/input/processed-images\")\n",
    "CKPT_ROOT        = Path(\"/kaggle/working/checkpoints\")\n",
    "EXPERIMENT       = \"wafer_pix2pix_AtoB_256_out1\"\n",
    "EXP_DIR          = CKPT_ROOT / EXPERIMENT\n",
    "\n",
    "# Training\n",
    "LOAD_SIZE        = 286\n",
    "CROP_SIZE        = 256\n",
    "INPUT_NC         = 3\n",
    "OUTPUT_NC        = 1\n",
    "BATCH_SIZE       = 4\n",
    "LR               = 0.0002\n",
    "BETA1            = 0.5\n",
    "N_EPOCHS         = 100\n",
    "N_EPOCHS_DECAY   = 50\n",
    "SAVE_EPOCH_FREQ  = 5\n",
    "SAVE_LATEST_FREQ = 2000\n",
    "DIRECTION        = \"AtoB\"\n",
    "\n",
    "# Kaggle Dataset autosync\n",
    "KDS_SLUG         = \"wafer-pix2pix-checkpoints\"\n",
    "KDS_POLL_MIN     = 8\n",
    "KDS_UPLOAD_DIR   = Path(\"/kaggle/working/_kds_upload\")\n",
    "KDS_DL_DIR       = Path(\"/kaggle/working/_kds_download\")\n",
    "\n",
    "def run(cmd, check=True, capture=False):\n",
    "    print(\"[$]\", cmd if isinstance(cmd,str) else \" \".join(shlex.quote(c) for c in cmd))\n",
    "    if capture:\n",
    "        return subprocess.run(cmd, check=check, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
    "    else:\n",
    "        return subprocess.run(cmd, check=check)\n",
    "\n",
    "# --- Data sanity ---\n",
    "assert DATAROOT.exists(), f\"Dataset folder not found: {DATAROOT}\"\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    p = DATAROOT/split\n",
    "    assert p.exists(), f\"Missing subfolder {split}\"\n",
    "    assert any(p.glob('**/*.*')), f\"No images found in {p}\"\n",
    "\n",
    "# --- Repo ---\n",
    "if not REPO.exists():\n",
    "    run([\"git\",\"clone\",\"--depth\",\"1\",GIT_URL,str(REPO)])\n",
    "\n",
    "# --- Kaggle CLI present ---\n",
    "out = run([sys.executable,\"-m\",\"pip\",\"show\",\"kaggle\"], check=False, capture=True)\n",
    "if \"Version:\" not in out:\n",
    "    run([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"kaggle\"])\n",
    "\n",
    "# --- Token ---\n",
    "KAGGLE_DIR = Path.home()/\".kaggle\"\n",
    "KAGGLE_JSON = KAGGLE_DIR/\"kaggle.json\"\n",
    "if KAGGLE_JSON.exists():\n",
    "    os.chmod(KAGGLE_JSON, 0o600)\n",
    "\n",
    "def get_kaggle_username():\n",
    "    if KAGGLE_JSON.exists():\n",
    "        try:\n",
    "            cfg = json.loads(KAGGLE_JSON.read_text())\n",
    "            if cfg.get(\"username\"):\n",
    "                return cfg[\"username\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return os.environ.get(\"KAGGLE_USERNAME\")\n",
    "\n",
    "KAGGLE_USER = get_kaggle_username()\n",
    "KDS_ID = f\"{KAGGLE_USER}/{KDS_SLUG}\" if KAGGLE_USER else None\n",
    "\n",
    "def ensure_kds_exists():\n",
    "    if not (KAGGLE_JSON.exists() and KAGGLE_USER):\n",
    "        return False\n",
    "    exists = False\n",
    "    try:\n",
    "        info = run([\"kaggle\",\"datasets\",\"list\",\"-u\",KAGGLE_USER,\"-p\",\"50\"], check=False, capture=True)\n",
    "        exists = any(f\"{KAGGLE_USER}/{KDS_SLUG}\" in line for line in info.splitlines())\n",
    "    except Exception:\n",
    "        pass\n",
    "    if exists:\n",
    "        return True\n",
    "    # create minimal private dataset\n",
    "    meta_dir = KDS_UPLOAD_DIR\n",
    "    meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (meta_dir/\"README.md\").write_text(\"# wafer pix2pix checkpoints\\n\")\n",
    "    metadata = {\n",
    "        \"title\": \"Wafer Pix2Pix Checkpoints\",\n",
    "        \"id\": f\"{KAGGLE_USER}/{KDS_SLUG}\",\n",
    "        \"licenses\": [{\"name\":\"CC0-1.0\"}],\n",
    "        \"isPrivate\": True\n",
    "    }\n",
    "    (meta_dir/\"dataset-metadata.json\").write_text(json.dumps(metadata))\n",
    "    run([\"kaggle\",\"datasets\",\"create\",\"-p\",str(meta_dir),\"-q\"], check=False)\n",
    "    return True\n",
    "\n",
    "def kds_version_upload(note=\"auto\"):\n",
    "    if not (KAGGLE_JSON.exists() and KAGGLE_USER):\n",
    "        return False\n",
    "    KDS_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    # clean temp\n",
    "    for p in KDS_UPLOAD_DIR.glob(\"*\"):\n",
    "        if p.is_file(): p.unlink()\n",
    "    # pack EXP_DIR\n",
    "    zip_path = KDS_UPLOAD_DIR/f\"{EXPERIMENT}_checkpoints.zip\"\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for f in EXP_DIR.rglob(\"*\"):\n",
    "            if f.is_file():\n",
    "                zf.write(f, arcname=str(f.relative_to(CKPT_ROOT)))\n",
    "    # ensure metadata exists\n",
    "    meta_json = KDS_UPLOAD_DIR/\"dataset-metadata.json\"\n",
    "    if not meta_json.exists():\n",
    "        meta = {\n",
    "            \"title\": \"Wafer Pix2Pix Checkpoints\",\n",
    "            \"id\": f\"{KAGGLE_USER}/{KDS_SLUG}\",\n",
    "            \"licenses\": [{\"name\":\"CC0-1.0\"}],\n",
    "            \"isPrivate\": True\n",
    "        }\n",
    "        meta_json.write_text(json.dumps(meta))\n",
    "    try:\n",
    "        run([\"kaggle\",\"datasets\",\"version\",\"-p\",str(KDS_UPLOAD_DIR),\"-m\",note,\"-r\",\"zip\",\"-q\"], check=True)\n",
    "        print(\"✅ Upload to Kaggle Dataset completed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Failed to upload to Kaggle Dataset:\", e)\n",
    "        return False\n",
    "\n",
    "def kds_has_version():\n",
    "    \"\"\"returns True if dataset exists AND has at least one downloadable file/version\"\"\"\n",
    "    if not (KAGGLE_JSON.exists() and KAGGLE_USER):\n",
    "        return False\n",
    "    try:\n",
    "        status = run([\"kaggle\",\"datasets\",\"status\",KDS_ID,\"-v\"], check=False, capture=True)\n",
    "        # If there's at least one file listed – it's considered ready\n",
    "        return (\"files:\" in status.lower() and \"error\" not in status.lower()) or (\"ready\" in status.lower())\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def kds_download_latest(max_tries=6, sleep_sec=20):\n",
    "    \"\"\"try to download latest version; if 404 on first run, skip gracefully\"\"\"\n",
    "    if not (KAGGLE_JSON.exists() and KAGGLE_USER):\n",
    "        return False\n",
    "    if not kds_has_version():\n",
    "        print(\"ℹ️ Dataset exists but likely has no version yet. Continuing without download (first run).\")\n",
    "        return False\n",
    "    KDS_DL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            run([\"kaggle\",\"datasets\",\"download\",\"-d\",KDS_ID,\"-p\",str(KDS_DL_DIR),\"-q\"], check=True)\n",
    "            # unzip all\n",
    "            for z in KDS_DL_DIR.glob(\"*.zip\"):\n",
    "                run([\"unzip\",\"-o\",str(z),\"-d\",str(KDS_DL_DIR)], check=True)\n",
    "            # restore into CKPT_ROOT\n",
    "            CKPT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "            for f in KDS_DL_DIR.rglob(\"*\"):\n",
    "                if f.is_file():\n",
    "                    dst = CKPT_ROOT / f.relative_to(KDS_DL_DIR)\n",
    "                    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    dst.write_bytes(f.read_bytes())\n",
    "            print(\"✅ Downloaded checkpoints from latest version.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"…Waiting for version to be published (or skip if first run). Error:\", str(e)[:120])\n",
    "            time.sleep(sleep_sec)\n",
    "    print(\"⚠️ No version downloaded (probably first run). Continuing without resume.\")\n",
    "    return False\n",
    "\n",
    "# ---------- ensure dataset & try download ----------\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if ensure_kds_exists():\n",
    "    kds_download_latest()\n",
    "\n",
    "# ---------- resume flags ----------\n",
    "continue_train = (EXP_DIR/\"latest_net_G.pth\").exists()\n",
    "epoch_count_arg = None\n",
    "iter_txt = EXP_DIR/\"iter.txt\"\n",
    "if iter_txt.exists():\n",
    "    try:\n",
    "        t = iter_txt.read_text().strip().split()\n",
    "        if t and t[0].isdigit():\n",
    "            epoch_count_arg = str(max(1, int(t[0]) + 1))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------- build train cmd (NO --display_id) ----------\n",
    "train_py = str(REPO/\"train.py\")\n",
    "cmd = [\n",
    "    sys.executable, train_py,\n",
    "    \"--dataroot\", str(DATAROOT),\n",
    "    \"--name\", EXPERIMENT,\n",
    "    \"--model\", \"pix2pix\",\n",
    "    \"--dataset_mode\", \"aligned\",\n",
    "    \"--direction\", DIRECTION,\n",
    "    \"--checkpoints_dir\", str(CKPT_ROOT),\n",
    "    \"--preprocess\", \"resize_and_crop\",\n",
    "    \"--load_size\", str(LOAD_SIZE),\n",
    "    \"--crop_size\", str(CROP_SIZE),\n",
    "    \"--input_nc\", str(INPUT_NC),\n",
    "    \"--output_nc\", str(OUTPUT_NC),\n",
    "    \"--batch_size\", str(BATCH_SIZE),\n",
    "    \"--n_epochs\", str(N_EPOCHS),\n",
    "    \"--n_epochs_decay\", str(N_EPOCHS_DECAY),\n",
    "    \"--lr\", str(LR),\n",
    "    \"--beta1\", str(BETA1),\n",
    "    \"--gan_mode\", \"vanilla\",\n",
    "    \"--lambda_L1\", \"100\",\n",
    "    \"--save_epoch_freq\", str(SAVE_EPOCH_FREQ),\n",
    "    \"--save_latest_freq\", str(SAVE_LATEST_FREQ),\n",
    "    \"--print_freq\", \"100\",\n",
    "]\n",
    "if continue_train:\n",
    "    cmd += [\"--continue_train\"]\n",
    "    if epoch_count_arg:\n",
    "        cmd += [\"--epoch_count\", epoch_count_arg]\n",
    "\n",
    "print(\">>> TRAIN CMD:\\n\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "\n",
    "# ---------- autosync thread ----------\n",
    "stop_flag = False\n",
    "def periodic_kds_uploader():\n",
    "    if not (KAGGLE_JSON.exists() and KAGGLE_USER):\n",
    "        return\n",
    "    last_upload_t = 0\n",
    "    last_sig = \"\"\n",
    "    while not stop_flag:\n",
    "        try:\n",
    "            parts = []\n",
    "            for f in EXP_DIR.rglob(\"*\"):\n",
    "                if f.is_file():\n",
    "                    st = f.stat()\n",
    "                    parts.append(f\"{f.relative_to(EXP_DIR)}:{st.st_size}:{int(st.st_mtime)}\")\n",
    "            sig = str(hash(\"|\".join(sorted(parts))))\n",
    "            now = time.time()\n",
    "            if (sig != last_sig) and (now - last_upload_t > KDS_POLL_MIN*60):\n",
    "                note = f\"auto sync at {time.strftime('%Y-%m-%d %H:%M')}\"\n",
    "                print(\">>> Checkpoints change detected → uploading new dataset version ...\")\n",
    "                if kds_version_upload(note=note):\n",
    "                    last_sig = sig\n",
    "                    last_upload_t = now\n",
    "        except Exception as e:\n",
    "            print(\"Uploader thread error:\", e)\n",
    "        time.sleep(30)\n",
    "\n",
    "uploader_th = threading.Thread(target=periodic_kds_uploader, daemon=True)\n",
    "uploader_th.start()\n",
    "\n",
    "# ---------- run training ----------\n",
    "ret = run(cmd, check=False)\n",
    "print(\">>> train.py exited with code:\", ret.returncode)\n",
    "\n",
    "# final sync\n",
    "if KAGGLE_JSON.exists() and KAGGLE_USER:\n",
    "    kds_version_upload(note=f\"final sync exit={ret.returncode}\")\n",
    "\n",
    "stop_flag = True\n",
    "time.sleep(1)\n",
    "print(\"DONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b78bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
